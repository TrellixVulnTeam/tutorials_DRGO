{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e7e251-38fe-4bd3-9774-5ad096b52544",
   "metadata": {},
   "source": [
    "# Tutorial: Reading data from S3 files and writing data in S3 files. There are two methods\n",
    "## Method 1\n",
    "1) Create a session using Boto3\n",
    "2) Get access to S3 resource\n",
    "3) Define the object with bucket name and filename\n",
    "4) Perform the Read(get) / Write(put) operation on the defined object\n",
    "\n",
    "## Method 2\n",
    "1) Create a boto3 client for S3 bucket for a given AWS region\n",
    "2) Perform read(get_object) / Write(Put_Object) operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070a82f2-8077-4bea-9e42-bf79627ecd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a131a6-6176-42bc-863e-0d8734db0706",
   "metadata": {},
   "source": [
    "## Method1: Get S3 resource access without Credentials (Default credentials linked to IAM profile will be used)\n",
    "- Create session and S3 resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecbea03-a75c-4a74-8a08-90e6211f23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Session With Boto3 with credentials\n",
    "session = boto3.Session()\n",
    "\n",
    "#Creating S3 Resource From the Session.\n",
    "s3_resource = session.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48900a55-4406-4567-a390-3ee61f5009aa",
   "metadata": {},
   "source": [
    "## Define a function to write data into S3 as file\n",
    "- Create a S3 Object and perform the required method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7fc7d8-d988-4bc0-b248-38135be99816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S3_WriteObject(bucketname,objectname,data):\n",
    "    # Creat S3 object with given bucket and filename\n",
    "    S3object = s3_resource.Object(bucketname, objectname)\n",
    "\n",
    "    # Write the content in a text file\n",
    "    response = S3object.put(Body=data)\n",
    "\n",
    "    # Verify the status of operation\n",
    "    status = response.get(\"ResponseMetadata\").get(\"HTTPStatusCode\")\n",
    "\n",
    "    if status == 200:\n",
    "        print(objectname, \"has been written successfully in S3\")\n",
    "    else:\n",
    "        print(f\"Unsuccessful S3 put_object response. Status - {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dad257-ce22-4834-a86f-8271e2570057",
   "metadata": {},
   "source": [
    "## Define a function to verify if the given object is present in the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2be961-f077-4f22-b683-6b342adb679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify if a object present in a given bucket\n",
    "def S3_VerifyObject(bucket,objectkey):\n",
    "    my_bucket = s3_resource.Bucket(bucket)\n",
    "    allbuckets = my_bucket.objects.all()\n",
    "    for object in allbuckets:\n",
    "        if object.key == objectkey:\n",
    "            print(objectkey, 'is present in the S3')\n",
    "            break\n",
    "    else:\n",
    "        print(objectkey, 'is not present in S3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40bbc46c-6419-4761-9d2e-fdec1ba84ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the bucket name \n",
    "bucket = 'mk-logs-from-cloudwatch'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70579f51-490f-4146-9b06-71021c0fcd82",
   "metadata": {},
   "source": [
    "## Upload a content in the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2768532-3a36-4fa0-b12a-1258d770d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name_20220825.txt has been written successfully in S3\n",
      "file_name_20220825.txt is present in the S3\n"
     ]
    }
   ],
   "source": [
    "# upload a .txt file in the S3 bucket\n",
    "txt_data = b'This is the content of the file uploaded from python boto3'\n",
    "\n",
    "filename = 'file_name_20220825.txt'\n",
    "\n",
    "S3_WriteObject(bucketname=bucket, objectname=filename, data=txt_data)\n",
    "\n",
    "# Verify if the file is present in the bucket\n",
    "S3_VerifyObject(bucket=bucket,objectkey=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca95133-3057-41cc-84d0-ceeed135dc5d",
   "metadata": {},
   "source": [
    "## Store data frame as csv in S3 bucekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f7c65c2-8984-484b-9431-a1c6f590463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d46ce2-fd0a-4dd0-81eb-732d113e69e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create a test data frame\n",
    "dict1 = {\"company\": ['TCS','WIPRO','INFOSYS','MICROSFT','GOOGLE','ORACLE'],\n",
    "         \"Location\": ['CHENNAI','MYSORE','MYSORE','HYDERABAD','MUMBAI','MUMBAI' ],\n",
    "         \"SIZE\": [40000,35000,45000,6000,5000,4000]}\n",
    "df1 = pd.DataFrame(dict1)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "937a7481-d4c4-4d54-b169-964ef944ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary buffer in a memory\n",
    "csv_buffer = StringIO()\n",
    "\n",
    "# Store the dataframe as csv file in the buffer\n",
    "df1.to_csv(csv_buffer,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fc3b820-f3b8-499b-94f8-e15e83833c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT_Companies_4.csv has been written successfully in S3\n",
      "IT_Companies_4.csv is present in the S3\n"
     ]
    }
   ],
   "source": [
    "# write the csv file into S3 bucket\n",
    "s3_object_name = 'IT_Companies_4.csv'\n",
    "\n",
    "# write the csv file to S3\n",
    "S3_WriteObject(bucketname=bucket, objectname=s3_object_name, data=csv_buffer.getvalue())\n",
    "\n",
    "# Verify if the file is present in the bucket\n",
    "S3_VerifyObject(bucket=bucket,objectkey=s3_object_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65307f-442a-468d-b5f7-9a14bb51464b",
   "metadata": {},
   "source": [
    "## Define a function to read a file from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee5384a4-ff26-42cf-98a7-81ae9954b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S3_ReadObject(bucketname,objectname):\n",
    "    # Creat S3 object with given bucket and filename\n",
    "    S3object = s3_resource.Object(bucketname, objectname)\n",
    "\n",
    "    # Write the content in a text file\n",
    "    response = S3object.get()\n",
    "\n",
    "    # Verify the status of operation\n",
    "    status = response.get(\"ResponseMetadata\").get(\"HTTPStatusCode\")\n",
    "\n",
    "    if status == 200:\n",
    "        print(\"File has been read successfully\")\n",
    "    else:\n",
    "        print(f\"Unsuccessful S3 put_object response. Status - {status}\")\n",
    "    \n",
    "    return response['Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337dc1b-87ea-4f3f-a1ed-61c039c83923",
   "metadata": {},
   "source": [
    "### Read a text file present in the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5267630f-e4ca-42af-98f9-011c3642b6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been read successfully\n",
      "b'This is the content of the file uploaded from python boto3'\n"
     ]
    }
   ],
   "source": [
    "objectname = 'file_name_20220825.txt'\n",
    "content = S3_ReadObject(bucket, objectname)\n",
    "text = content.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12921b-9341-4738-89f8-4dc190e231e9",
   "metadata": {},
   "source": [
    "### Read a csv file from S3 into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bee5e4a-8d95-4ac5-b06e-fbd20e868f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been read successfully\n",
      "    company   Location   SIZE\n",
      "0       TCS    CHENNAI  40000\n",
      "1     WIPRO     MYSORE  35000\n",
      "2   INFOSYS     MYSORE  45000\n",
      "3  MICROSFT  HYDERABAD   6000\n",
      "4    GOOGLE     MUMBAI   5000\n",
      "5    ORACLE     MUMBAI   4000\n"
     ]
    }
   ],
   "source": [
    "# read the csv file from S3 bucket\n",
    "objectname = 'IT_Companies_4.csv'\n",
    "content = S3_ReadObject(bucket, objectname)\n",
    "\n",
    "# Read the data into a data frame\n",
    "df2 = pd.read_csv(content)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1470895c-c556-48b1-b42d-f07850a09240",
   "metadata": {},
   "source": [
    "## Method2: ACCESS S3 USING Boto 3 CLIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2fd615-35c4-4486-a907-3f15feab0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a S3 client\n",
    "resource = 's3'\n",
    "region = 'us-east-2'\n",
    "s3_client = boto3.client(service_name=resource,region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872a23f-6e00-43ec-a97a-7409cdbfefab",
   "metadata": {},
   "source": [
    "## Define a function to write content into S3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "397d0fa8-278a-48fd-a06b-4fe29be5967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S3ClientWrite(data,bucket,objectkey):\n",
    "    s3_client.put_object(Body=data, Bucket=bucket, Key=objectkey)\n",
    "    \n",
    "    # Verify if the file is present in the S3 bucket\n",
    "    for item in s3_client.list_objects(Bucket=bucket).items():\n",
    "        if item[0] == 'Contents':\n",
    "            for listitem in item[1]:\n",
    "                if listitem['Key'] == objectkey:\n",
    "                    print(objectkey, 'has been saved in the S3 bucket')\n",
    "                    break\n",
    "            else:\n",
    "                print(objectkey, 'is not present in the S3 bucket')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f24b37-e553-4b8b-b7fc-737fdaa0f50f",
   "metadata": {},
   "source": [
    "## Write a text data into a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea842d67-5c9b-448d-bf35-89f1bccbd07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1_Boto3Client.txt has been saved in the S3 bucket\n"
     ]
    }
   ],
   "source": [
    "# upload a .txt file in the S3 bucket\n",
    "txt_data = b'This is the content of the file uploaded using boto3 client'\n",
    "bucket = 'mk-logs-from-cloudwatch'\n",
    "objectkey = 'test1_Boto3Client.txt'\n",
    "S3ClientWrite(txt_data, bucket, objectkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ebe49b-c531-445b-8062-596f0c5bc491",
   "metadata": {},
   "source": [
    "## Write a dataframe into a csv file in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee4de7b6-1844-4787-b048-561534d20ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT_Companies_Boto3Client.csv has been saved in the S3 bucket\n"
     ]
    }
   ],
   "source": [
    "# write the csv file to S3\n",
    "objectkey = 'IT_Companies_Boto3Client.csv'\n",
    "S3ClientWrite(csv_buffer.getvalue(), bucket, objectkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a3433-9c06-4737-b187-7c7799cb66ef",
   "metadata": {},
   "source": [
    "## Define a function to read a file from S3 bucket using S3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9266775e-6750-4963-82e7-f062e7183643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S3ClientRead(bucket,objectkey):\n",
    "        \n",
    "    # Get the file if it is present in the S3 bucket. Otherwise, print error message\n",
    "    for item in s3_client.list_objects(Bucket=bucket).items():\n",
    "        if item[0] == 'Contents':\n",
    "            for listitem in item[1]:\n",
    "                if listitem['Key'] == objectkey:\n",
    "                    print(objectkey, 'is present in the S3 bucket')\n",
    "                    response = s3_client.get_object(Bucket=bucket, Key=objectkey)\n",
    "                    return (response['Body'])\n",
    "                    break\n",
    "            else:\n",
    "                print(objectkey, 'is not present in the S3 bucket')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4162cd-ec93-42fe-8110-9b1c147e6ebd",
   "metadata": {},
   "source": [
    "## Read a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4de8d40-2b3d-4703-9be9-21d1efce00bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name.txt is present in the S3 bucket\n",
      "b'This is the content of the file uploaded from python boto3'\n"
     ]
    }
   ],
   "source": [
    "data = S3ClientRead('mk-logs-from-cloudwatch','file_name.txt')\n",
    "string = data.read()\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d64cd-96a2-48e6-bb95-099f8986cafa",
   "metadata": {},
   "source": [
    "## Read a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db9b053e-9445-41e5-a23d-260b897f5a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT_Companies_Boto3Client.csv is present in the S3 bucket\n",
      "    company   Location   SIZE\n",
      "0       TCS    CHENNAI  40000\n",
      "1     WIPRO     MYSORE  35000\n",
      "2   INFOSYS     MYSORE  45000\n",
      "3  MICROSFT  HYDERABAD   6000\n",
      "4    GOOGLE     MUMBAI   5000\n",
      "5    ORACLE     MUMBAI   4000\n"
     ]
    }
   ],
   "source": [
    "data = S3ClientRead('mk-logs-from-cloudwatch','IT_Companies_Boto3Client.csv')\n",
    "df=pd.read_csv(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c0f92-999f-4127-a0a4-f51b017c7854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
